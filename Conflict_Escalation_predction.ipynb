{"cells":[{"cell_type":"code","execution_count":5,"id":"efdfaeed","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23698,"status":"ok","timestamp":1744226338882,"user":{"displayName":"koolgreg2009","userId":"03315174616297252320"},"user_tz":240},"id":"efdfaeed","outputId":"ef1d29e5-7de6-437a-b6ae-29cab4525a1a","scrolled":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import pandas as pd\n","\n","df_preds = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/STA130/test_predictions.csv')\n","df_preds"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":339},"id":"Cc9aw8_0_rbk","executionInfo":{"status":"error","timestamp":1744228231084,"user_tz":240,"elapsed":38,"user":{"displayName":"koolgreg2009","userId":"03315174616297252320"}},"outputId":"8777d342-37ad-4f27-e15d-448d18c00b35"},"id":"Cc9aw8_0_rbk","execution_count":11,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/STA130/test_predictions.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-5b070628b487>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/STA130/test_predictions.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf_preds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/STA130/test_predictions.csv'"]}]},{"cell_type":"code","source":["\n","df_preds = pd.read_csv('test_predictions.csv')\n","df_preds"],"metadata":{"id":"c35TRnVP_TEm"},"id":"c35TRnVP_TEm","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"f130d9a4","metadata":{"executionInfo":{"elapsed":273,"status":"aborted","timestamp":1744226253059,"user":{"displayName":"koolgreg2009","userId":"03315174616297252320"},"user_tz":240},"id":"f130d9a4"},"outputs":[],"source":["df_indicators = pd.read_csv('country_indicators.csv')\n","df_indicators"]},{"cell_type":"code","execution_count":null,"id":"f0b46ff2","metadata":{"executionInfo":{"elapsed":284,"status":"aborted","timestamp":1744226253072,"user":{"displayName":"koolgreg2009","userId":"03315174616297252320"},"user_tz":240},"id":"f0b46ff2"},"outputs":[],"source":["df = df_preds.merge(df_indicators, left_on='iso3', right_on='iso3', how='inner')\n","df"]},{"cell_type":"code","execution_count":null,"id":"e1dcf57a","metadata":{"executionInfo":{"elapsed":0,"status":"aborted","timestamp":1744226253073,"user":{"displayName":"koolgreg2009","userId":"03315174616297252320"},"user_tz":240},"id":"e1dcf57a"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"fe0ea820","metadata":{"executionInfo":{"elapsed":284,"status":"aborted","timestamp":1744226253073,"user":{"displayName":"koolgreg2009","userId":"03315174616297252320"},"user_tz":240},"id":"fe0ea820"},"outputs":[],"source":["# Okay, so we first need to get the Probability Prediciton \"Error\"\n","import numpy as np\n","df['error_transformer'] = np.abs(df.y_true_transformer-df.y_pred_proba_transformer)\n","df['error_ffnn'] = np.abs(df.y_true_ffnn-df.y_pred_proba_ffnn)\n","df['error_xgboost'] = np.abs(df.y_true_xgboost-df.y_pred_proba_xgboost)"]},{"cell_type":"code","execution_count":null,"id":"31e33392","metadata":{"executionInfo":{"elapsed":283,"status":"aborted","timestamp":1744226253074,"user":{"displayName":"koolgreg2009","userId":"03315174616297252320"},"user_tz":240},"id":"31e33392"},"outputs":[],"source":["# But, then, what I wanted to do first was look at those \"Progress Indicator\" variables that kept\n","# getting mentioned; but, specifically, the actual indicator variable versions of these...\n","# This is code Evan Wheeler gave me and it does the trick to make the indicator variables I want\n","\n","# make df of column names and their dtypes\n","df_cols = pd.DataFrame(df.dtypes, columns=('coldtype',)).reset_index().rename(columns={'index': 'colname'})\n","df_cols['coldtype'] = df_cols['coldtype'].astype('string')\n","# adjusting a potentially useful variable that might be considered label\n","df['fsi_rank'] = df['fsi_rank'].astype('string').str.replace(r'\\D', '', regex=True).replace('', pd.NA)\n","# get list of numeric variables\n","num_vars = df_cols.query(\"coldtype=='float64'\")['colname'].values\n","# these could be useful; but, I'm ignoring them for now to keep the demonstration simpler...\n","\n","import itertools\n","\n","# Indicator variables are often called \"one hot\" encodings\n","def one_hot(df, cols):\n","    \"\"\" One-hot encode given `cols` and add as new columns\n","        to `df`\n","\n","        Returns tuple of `df` with new columns and list of\n","        new column names.\n","    \"\"\"\n","    new_cols = list()\n","    new_col_names = list()\n","    for each in cols:\n","        dummies = pd.get_dummies(df[each], prefix=each)\n","        new_cols.append(dummies)\n","        new_col_names.append(dummies.columns.values)\n","\n","    df = pd.concat([df]+new_cols, axis=1)\n","    new_col_names = list(itertools.chain.from_iterable(new_col_names))\n","    return df, new_col_names\n","\n","# categorical variables we will turn into indicator (\"one hot\") variables\n","cat_vars = ['hdr_region', 'wbi_income_group', 'wbi_lending_category']\n","cont_vars = ['fsi_x1:_external_intervention', 'sowc_education__learning_literacy-rate-2014-2022_youth-15-24-years-literacy-rate_male', 'fsi_p1:_state_legitimacy', 'fsi_p2:_public_services', 'fsi_p3:_human_rights', 'fsi_c1:_security_apparatus', 'fsi_s1_demographic_pressures']\n","# Prof. Schwartz'z Note:\n","# I'm not sure if there are other categorical variables in this data that could also be transformed\n","# These are just the ones Evan initially used as examples as he described the objectives of the project\n","# get one hot encodings\n","df_oh, oh_cols = one_hot(df, cat_vars)\n","df_oh = df_oh.drop(columns=cat_vars)\n","cont_col = []\n","\n","\n","df_oh[['error_transformer','error_ffnn','error_xgboost'] + oh_cols]\n","\n"]},{"cell_type":"code","execution_count":null,"id":"eb5e26e3","metadata":{"id":"eb5e26e3","executionInfo":{"status":"aborted","timestamp":1744226253081,"user_tz":240,"elapsed":290,"user":{"displayName":"koolgreg2009","userId":"03315174616297252320"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"abd21f89","metadata":{"executionInfo":{"elapsed":296,"status":"aborted","timestamp":1744226253087,"user":{"displayName":"koolgreg2009","userId":"03315174616297252320"},"user_tz":240},"id":"abd21f89"},"outputs":[],"source":["# For the analysis demonstration below I'm not going to use the following indicator variables:\n","# `'fsi_category_Stable', 'hdr_hdicode_Low', 'wbi_income_group_High income',\n","# 'wbi_lending_category_IBRD', 'wbi_other_(emu_or_hipc)_HIPC'` and `'hdr_region_SSA'`\n","# This makes these categories the \"baseline\" categories for each of these variables.\n","\n","# I initially thought I was choosing these because I thought the names suggested\n","# they might not be a conflict region; or, I just kinda randomly picked one\n","# because I couldn't tell what they meant...\n","# I should have probably first tried to figure out what they meant...\n","\n","# But, anyway, for now, this means my analysis is just using the following indicator variables:\n","reduced_oh_cols = \\\n","[\n"," 'hdr_region_AS',\n"," 'hdr_region_EAP',\n"," 'hdr_region_ECA',\n"," 'hdr_region_LAC',\n"," 'hdr_region_SA',\n"," 'wbi_income_group_Low income',\n"," 'wbi_income_group_Lower middle income',\n"," 'wbi_income_group_Upper middle income',\n"," 'wbi_lending_category_Blend',\n"," 'wbi_lending_category_IDA',\n"," 'fsi_x1:_external_intervention',\n"," 'fsi_s1:_demographic_pressures',\n"," 'fsi_p1:_state_legitimacy',\n"," 'fsi_p2:_public_services',\n"," 'fsi_p3:_human_rights',\n"," 'fsi_c1:_security_apparatus',\n"," 'sowc_demographics__population-thousands-2021_total',\n"," 'sowc_demographics__life-expectancy-at-birth-years_2000-0',\n"," 'sowc_demographics__life-expectancy-at-birth-years_1970',\n"," 'sowc_demographics__population-thousands-2021_under-18',\n"," 'fsi_e3:_human_flight_and_brain_drain',\n"," 'sowc_demographics__annual-number-of-births-thousands-2021_2020-2030-a',\n"," 'sowc_demographics__net-migration-rate-per-1000-population-2021_old-age-dependency-ratio_2020-2030-a',\n"," 'sowc_migration__international-migrant-stock-2020_total-thousands'\n","\n","\n","]\n","# And so for now use them and take a look at them below"]},{"cell_type":"code","execution_count":null,"id":"af22d2da","metadata":{"executionInfo":{"elapsed":297,"status":"aborted","timestamp":1744226253088,"user":{"displayName":"koolgreg2009","userId":"03315174616297252320"},"user_tz":240},"id":"af22d2da"},"outputs":[],"source":["df_oh['model_transformer'] = df_oh['error_transformer'].astype(str)*0+\"transformer\"\n","df_oh['model_ffnn'] = df_oh['error_ffnn'].astype(str)*0+\"ffnn\"\n","df_oh['model_xgboost'] = df_oh['error_xgboost'].astype(str)*0+\"xgboost\"\n"]},{"cell_type":"markdown","id":"abc75e1e","metadata":{"id":"abc75e1e"},"source":["## Correlation heatmap\n",">The correlation heatmap gives a visusal representation of the correlation between each indicator. In this case, a dark color of blue or red suggests a high correlation, either proportional or inversely proportional. If two covariates have high correlation, this introduces multicollinearity in the model, where two covariates predict in similar ways. This weakens the predicting power of the regression, hence it is to our interest to remove one of them."]},{"cell_type":"code","execution_count":null,"id":"2e14e614","metadata":{"executionInfo":{"elapsed":295,"status":"aborted","timestamp":1744226253088,"user":{"displayName":"koolgreg2009","userId":"03315174616297252320"},"user_tz":240},"id":"2e14e614","scrolled":true},"outputs":[],"source":["# Do indicator values correlate with model performance values?\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# A good function from Evan Wheeler I've edited just a little bit\n","def corr_heatmap(df):\n","    # plot correlation heatmap based on code from:\n","    # https://medium.com/@nikolh92/helpful-visualisations-for-linear-regression-646a5648ad9d\n","    sns.set(style=\"white\")\n","    corr = df.corr()\n","    mask = np.zeros_like(corr, dtype=bool)\n","    #mask[np.triu_indices_from(mask)] = True\n","    fig, ax = plt.subplots(figsize=(20, 16))\n","    cmap = sns.diverging_palette(10, 220, as_cmap=True)\n","    return sns.heatmap(corr, mask=mask, cmap=cmap, vmin=-1, vmax=1, center=0, square=True,\n","                       linewidths=.5, annot=False, cbar_kws={\"shrink\": .5})\n","\n","corr_heatmap(df_oh[['error_transformer','error_ffnn','error_xgboost'] + reduced_oh_cols])\n","_ = plt.axhline(y=3, c='k'); plt.axvline(x=3, c='k')"]},{"cell_type":"code","execution_count":null,"id":"f303b093","metadata":{"id":"f303b093","executionInfo":{"status":"aborted","timestamp":1744226253088,"user_tz":240,"elapsed":295,"user":{"displayName":"koolgreg2009","userId":"03315174616297252320"}}},"outputs":[],"source":[]},{"cell_type":"markdown","id":"1164a188","metadata":{"id":"1164a188"},"source":["## Removing indicators with high correlation\n"]},{"cell_type":"code","execution_count":null,"id":"3295a645","metadata":{"executionInfo":{"elapsed":311,"status":"aborted","timestamp":1744226253104,"user":{"displayName":"koolgreg2009","userId":"03315174616297252320"},"user_tz":240},"id":"3295a645"},"outputs":[],"source":["reduced_oh_cols.remove(\"sowc_demographics__population-thousands-2021_total\")\n","reduced_oh_cols.remove(\"sowc_demographics__annual-number-of-births-thousands-2021_2020-2030-a\")\n","reduced_oh_cols.remove(\"fsi_p1:_state_legitimacy\")\n","reduced_oh_cols.remove(\"sowc_demographics__life-expectancy-at-birth-years_1970\")\n","reduced_oh_cols.remove(\"sowc_demographics__life-expectancy-at-birth-years_2000-0\")"]},{"cell_type":"code","execution_count":null,"id":"f0eba07b","metadata":{"executionInfo":{"elapsed":314,"status":"aborted","timestamp":1744226253109,"user":{"displayName":"koolgreg2009","userId":"03315174616297252320"},"user_tz":240},"id":"f0eba07b"},"outputs":[],"source":["# Do indicator values correlate with model performance values?\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# A good function from Evan Wheeler I've edited just a little bit\n","def corr_heatmap(df):\n","    # plot correlation heatmap based on code from:\n","    # https://medium.com/@nikolh92/helpful-visualisations-for-linear-regression-646a5648ad9d\n","    sns.set(style=\"white\")\n","    corr = df.corr()\n","    mask = np.zeros_like(corr, dtype=bool)\n","    #mask[np.triu_indices_from(mask)] = True\n","    fig, ax = plt.subplots(figsize=(20, 16))\n","    cmap = sns.diverging_palette(10, 220, as_cmap=True)\n","    return sns.heatmap(corr, mask=mask, cmap=cmap, vmin=-1, vmax=1, center=0, square=True,\n","                       linewidths=.5, annot=False, cbar_kws={\"shrink\": .5})\n","\n","corr_heatmap(df_oh[['error_transformer','error_ffnn','error_xgboost'] + reduced_oh_cols])\n","_ = plt.axhline(y=3, c='k'); plt.axvline(x=3, c='k')"]},{"cell_type":"code","execution_count":null,"id":"794500f0","metadata":{"executionInfo":{"elapsed":313,"status":"aborted","timestamp":1744226253109,"user":{"displayName":"koolgreg2009","userId":"03315174616297252320"},"user_tz":240},"id":"794500f0"},"outputs":[],"source":["# This will be used to make the (additional) indicator variables of which model a prediction corresponds to\n","df_oh['model_transformer'] = df_oh['error_transformer'].astype(str)*0+\"transformer\"\n","df_oh['model_ffnn'] = df_oh['error_ffnn'].astype(str)*0+\"ffnn\"\n","df_oh['model_xgboost'] = df_oh['error_xgboost'].astype(str)*0+\"xgboost\"\n","\n","# The amount of error might change depending on if the prediction is positive or negative\n","# so this indicates if it was a postive or negative prediction\n","df_oh['prediction_transformer'] = df.y_true_transformer.astype(int) # actual outcome whether its conflict or no conflict?\n","df_oh['prediction_ffnn'] = df.y_pred_ffnn.astype(int)\n","df_oh['prediction_xgboost'] = df.y_true_xgboost.astype(int)\n","\n","# This \"stacks\" all the predictions together on top of each other so they can all be analyzed together:\n","# (make sure you understand what this is actually doing and why!)\n","design_matrix = \\\n","pd.concat([df_oh[['error_transformer', 'model_transformer', 'prediction_transformer']+reduced_oh_cols].rename(columns={'error_transformer':'error','model_transformer':'model','prediction_transformer':'predicts1'}),\n","           df_oh[['error_ffnn', 'model_ffnn', 'prediction_ffnn']+reduced_oh_cols].rename(columns={'error_ffnn':'error','model_ffnn':'model','prediction_ffnn':'predicts1'}),\n","           df_oh[['error_xgboost', 'model_xgboost', 'prediction_xgboost']+reduced_oh_cols].rename(columns={'error_xgboost':'error','model_xgboost':'model','prediction_xgboost':'predicts1'})],\n","          ignore_index=True)\n","\n","# 0. design_matrix[reduced_oh_cols] effects at \"baseline\" (`ffnn` predicts 0)\n","\n","# 1. design_matrix[reduced_oh_cols]*predicts1 offset changes to \"baseline\" when prediction is 1\n","design_matrix.predicts1 # is the intercept offset\n","for x in reduced_oh_cols:\n","    design_matrix[x+' X predicts1'] = design_matrix[x]*design_matrix['predicts1']\n","\n","# 2. design_matrix[reduced_oh_cols]*`transformer`/`xgboost` additional offset changes to \"baseline\"\n","# when prediction is made by `transformer`/`xgboost` for any prediction (0 or 1)\n","design_matrix['transformer'] = (design_matrix['model']==\"transformer\").astype(int) # intercept offset\n","design_matrix['xgboost'] = (design_matrix['model']==\"xgboost\").astype(int) # intercept offset\n","for x in reduced_oh_cols:\n","    design_matrix[x+' X transformer'] = design_matrix[x]*design_matrix['transformer']\n","    design_matrix[x+' X xgboost'] = design_matrix[x]*design_matrix['xgboost']\n","\n","# 3. design_matrix[reduced_oh_cols]*`transformer_predicts1`/`xgboost_predicts1`\n","# additional offset changes to \"baseline\" for non `ffnn` 1 predictions\n","design_matrix['transformer X predicts1'] = design_matrix['transformer']*design_matrix['predicts1']\n","design_matrix['xgboost X predicts1'] = design_matrix['xgboost']*design_matrix['predicts1']\n","for x in reduced_oh_cols:\n","    design_matrix[x+' X transformer X predicts1'] = design_matrix[x]*design_matrix['transformer X predicts1']\n","    design_matrix[x+' X xgboost X predicts1'] = design_matrix[x]*design_matrix['xgboost X predicts1']\n","\n","# This is to address the \"DataFrame is highly fragmented\" warning that's being flagged below\n","design_matrix = design_matrix.copy()\n","y = design_matrix['error']\n","del design_matrix['error']\n","del design_matrix['model']\n","design_matrix#.columns"]},{"cell_type":"code","execution_count":null,"id":"289f391c","metadata":{"executionInfo":{"elapsed":312,"status":"aborted","timestamp":1744226253110,"user":{"displayName":"koolgreg2009","userId":"03315174616297252320"},"user_tz":240},"id":"289f391c"},"outputs":[],"source":["import statsmodels.api as sm\n","\n","model_0_variables = design_matrix.columns.tolist()\n","model_0 = sm.OLS(y, sm.add_constant(design_matrix[model_0_variables]))\n","model_0.fit().summary()\n","\n","# Assuming model_0.fit().summary() returns a Summary object\n","#summary = model_0.fit().summary()\n","\n","# Extract the p-values and coefficients into a DataFrame\n","#summary_df = pd.DataFrame(summary.tables[1].data[1:], columns=summary.tables[1].data[0])\n","\n","# Convert p-values to numeric (they may be strings)\n","#summary_df['P>|t|'] = pd.to_numeric(summary_df['P>|t|'])\n","\n","# Sort by p-value in descending order\n","#sorted_summary = summary_df.sort_values(by='P>|t|', ascending=False)\n","\n","# Display or use sorted_summary as needed\n","# print(sorted_summary)"]},{"cell_type":"code","execution_count":null,"id":"f5a1e852","metadata":{"executionInfo":{"elapsed":311,"status":"aborted","timestamp":1744226253110,"user":{"displayName":"koolgreg2009","userId":"03315174616297252320"},"user_tz":240},"id":"f5a1e852"},"outputs":[],"source":["design_matrix.shape\n","#doing so we see that there are interactions that do not occur many times"]},{"cell_type":"code","execution_count":null,"id":"b984e7af","metadata":{"id":"b984e7af","executionInfo":{"status":"aborted","timestamp":1744226253110,"user_tz":240,"elapsed":309,"user":{"displayName":"koolgreg2009","userId":"03315174616297252320"}}},"outputs":[],"source":["design_matrix.loc[:,design_matrix.sum()>20].shape"]},{"cell_type":"markdown","id":"9d520705","metadata":{"id":"9d520705"},"source":["##  We can see that there are 27 interactions that occured less than 20 times. Because interactions with low occurance rates makes it difficult to estimate the error prediction rate, as they did not occur many  We'll restrict ourselves to only examing categories that happen at least 20 or more times.  \n"]},{"cell_type":"markdown","id":"b708be5f","metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1701630396508,"user":{"displayName":"Prisha Patel","userId":"07646472901452137965"},"user_tz":300},"id":"b708be5f"},"source":[]},{"cell_type":"code","execution_count":null,"id":"e0a24d46","metadata":{"executionInfo":{"elapsed":308,"status":"aborted","timestamp":1744226253110,"user":{"displayName":"koolgreg2009","userId":"03315174616297252320"},"user_tz":240},"id":"e0a24d46"},"outputs":[],"source":["design_matrix.loc[:,design_matrix.sum() > 20].shape #for interpretability"]},{"cell_type":"code","execution_count":null,"id":"d0bcf0c3","metadata":{"executionInfo":{"elapsed":308,"status":"aborted","timestamp":1744226253111,"user":{"displayName":"koolgreg2009","userId":"03315174616297252320"},"user_tz":240},"id":"d0bcf0c3"},"outputs":[],"source":["model_1_variables = design_matrix.loc[:,design_matrix.sum()>20].columns.tolist()\n","model_1 = sm.OLS(y, sm.add_constant(design_matrix[model_1_variables]))\n","model_1.fit().summary()"]},{"cell_type":"markdown","id":"32348bca","metadata":{"id":"32348bca"},"source":["We will be doing backwards selection. Backward selection is a variable selection method used in the context of regression analysis. The goal of backward selection is to iteratively remove the least significant predictors from a model until a satisfactory or optimal model is achieved.\n","\n","GPT\n","\n"]},{"cell_type":"markdown","id":"e802860a","metadata":{"id":"e802860a"},"source":["## We can remove interactions with a p value greater than 0.10 first. This is because we want to do an initial filtering to examine what the model is having removed the interactions with a p value that have no evidence against the null hypothesis."]},{"cell_type":"code","execution_count":null,"id":"c6d0ff7c","metadata":{"executionInfo":{"elapsed":307,"status":"aborted","timestamp":1744226253111,"user":{"displayName":"koolgreg2009","userId":"03315174616297252320"},"user_tz":240},"id":"c6d0ff7c"},"outputs":[],"source":["model_2_variables = model_1_variables.copy()\n","\n","# Manual \"Backwards Selection\"\n","# - I removed the variables below, bottom to top\n","# - To see my steps comment the removals, then uncomment one at a time, from bottom to top\n","#   re-running the cell each time#model_2_variables.remove(\"sowc_demographics__population-thousands-2021_under-18\")#\n","model_2_variables.remove(\"hdr_region_EAP X transformer\")\n","model_2_variables.remove(\"hdr_region_ECA X transformer\")\n","model_2_variables.remove(\"wbi_income_group_Upper middle income X transformer\")\n","model_2_variables.remove(\"fsi_x1:_external_intervention X transformer\")#\n","model_2_variables.remove(\"sowc_demographics__population-thousands-2021_under-18\")\n","model_2_variables.remove(\"sowc_demographics__population-thousands-2021_under-18 X xgboost X predicts1\")\n","model_2_variables.remove(\"sowc_demographics__population-thousands-2021_under-18 X predicts1\")#\n","model_2_variables.remove(\"fsi_x1:_external_intervention\")#\n","model_2_variables.remove(\"fsi_c1:_security_apparatus\")#\n","model_2_variables.remove(\"sowc_demographics__population-thousands-2021_under-18 X xgboost\")#\n","model_2_variables.remove(\"fsi_p3:_human_rights X xgboost\")#\n","model_2_variables.remove(\"wbi_income_group_Low income\")#\n","model_2_variables.remove(\"fsi_p2:_public_services X xgboost X predicts1\")#\n","model_2_variables.remove(\"wbi_income_group_Lower middle income X transformer\")#\n","model_2_variables.remove(\"fsi_e3:_human_flight_and_brain_drain\")#\n","model_2_variables.remove(\"fsi_p3:_human_rights\")#\n","model_2_variables.remove(\"hdr_region_AS\")#\n","model_2_variables.remove(\"wbi_income_group_Low income X predicts1\")#\n","model_2_variables.remove(\"wbi_lending_category_IDA X transformer\")#\n","model_2_variables.remove(\"fsi_s1:_demographic_pressures X transformer\")#\n","model_2_variables.remove(\"fsi_s1:_demographic_pressures X xgboost X predicts1\")#\n","model_2_variables.remove(\"fsi_p3:_human_rights X transformer X predicts1\")#\n","model_2_variables.remove(\"wbi_lending_category_IDA X xgboost\")#\n","model_2_variables.remove(\"wbi_lending_category_Blend X predicts1\")#\n","model_2_variables.remove(\"sowc_demographics__net-migration-rate-per-1000-population-2021_old-age-dependency-ratio_2020-2030-a\")#\n","model_2_variables.remove(\"hdr_region_ECA\")#\n","model_2_variables.remove(\"hdr_region_SA\")#\n","model_2_variables.remove(\"xgboost\")#\n","model_2_variables.remove(\"hdr_region_ECA X xgboost\")#\n","model_2_variables.remove(\"fsi_p3:_human_rights X predicts1\")#\n","model_2_variables.remove(\"wbi_income_group_Lower middle income X xgboost X predicts1\")#\n","model_2_variables.remove(\"fsi_x1:_external_intervention X transformer X predicts1\")#\n","model_2_variables.remove(\"sowc_demographics__net-migration-rate-per-1000-population-2021_old-age-dependency-ratio_2020-2030-a X transformer X predicts1\")#\n","model_2_variables.remove(\"sowc_demographics__net-migration-rate-per-1000-population-2021_old-age-dependency-ratio_2020-2030-a X xgboost X predicts1\")#\n","model_2_variables.remove(\"fsi_p3:_human_rights X xgboost X predicts1\")#\n","model_2_variables.remove(\"xgboost X predicts1\")#\n","model_2_variables.remove(\"fsi_x1:_external_intervention X xgboost\")#\n","model_2_variables.remove(\"hdr_region_LAC X transformer\")#\n","model_2_variables.remove(\"fsi_x1:_external_intervention X predicts1\")#\n","model_2_variables.remove(\"fsi_s1:_demographic_pressures X predicts1\")#\n","model_2_variables.remove(\"fsi_p2:_public_services X xgboost\")#\n","model_2_variables.remove(\"sowc_migration__international-migrant-stock-2020_total-thousands X transformer\")#\n","model_2_variables.remove(\"sowc_migration__international-migrant-stock-2020_total-thousands X xgboost\")#\n","model_2_variables.remove(\"sowc_migration__international-migrant-stock-2020_total-thousands X transformer X predicts1\")#\n","model_2_variables.remove(\"wbi_lending_category_IDA X transformer X predicts1\")#\n","model_2_variables.remove(\"sowc_demographics__net-migration-rate-per-1000-population-2021_old-age-dependency-ratio_2020-2030-a X predicts1\")#\n","model_2_variables.remove(\"fsi_e3:_human_flight_and_brain_drain X transformer\")#\n","model_2_variables.remove(\"wbi_income_group_Low income X xgboost\")#\n","model_2_variables.remove(\"wbi_income_group_Low income X transformer\")#\n","model_2_variables.remove(\"transformer\")#\n","model_2_variables.remove(\"fsi_p2:_public_services X predicts1\")#\n","model_2_variables.remove(\"wbi_income_group_Upper middle income X predicts1\")#\n","model_2_variables.remove(\"fsi_e3:_human_flight_and_brain_drain X xgboost X predicts1\")#\n","model_2_variables.remove(\"fsi_c1:_security_apparatus X predicts1\")#\n","model_2_variables.remove(\"fsi_p2:_public_services\")#\n","model_2_variables.remove(\"wbi_income_group_Upper middle income\")#\n","model_2_variables.remove(\"hdr_region_EAP\")#\n","model_2_variables.remove(\"wbi_lending_category_IDA\")#\n","model_2_variables.remove(\"wbi_lending_category_IDA X predicts1\")#\n","model_2_variables.remove(\"sowc_migration__international-migrant-stock-2020_total-thousands X predicts1\")#\n","model_2_variables.remove(\"sowc_demographics__net-migration-rate-per-1000-population-2021_old-age-dependency-ratio_2020-2030-a X transformer\")#\n","model_2_variables.remove(\"fsi_x1:_external_intervention X xgboost X predicts1\")#\n","model_2_variables.remove(\"sowc_migration__international-migrant-stock-2020_total-thousands X xgboost X predicts1\")#\n","model_2_variables.remove(\"wbi_lending_category_Blend\")#\n","model_2_variables.remove(\"hdr_region_AS X xgboost\")#\n","model_2_variables.remove(\"hdr_region_LAC\") #0.955\n","model_2_variables.remove(\"fsi_s1:_demographic_pressures X xgboost\")#0.979\n","model_2_variables.remove(\"predicts1\") #0.991\n","\n","\n","model_2 = sm.OLS(y, sm.add_constant(design_matrix[model_2_variables]))\n","model_2.fit().summary()"]},{"cell_type":"markdown","id":"de4a1ff3","metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1701630396509,"user":{"displayName":"Prisha Patel","userId":"07646472901452137965"},"user_tz":300},"id":"de4a1ff3"},"source":["Now all of our interactions are below the p value of 0.1 , indicating there is weak evidence against hypothesis or stronger\n","notes:\n","- cond number is really high suggesting multicolinearity\n","- r squared is 0.5, not bad\n","- removed the larger p values first (this was kind of rough we might need to go back i just sped through.) removed the ones above 0.9, then 0.5, and the 0.2- 0.1. This is important as removing interactions with very high p value influences the p values of the rest\n","-"]},{"cell_type":"code","execution_count":null,"id":"d50ed051","metadata":{"id":"d50ed051","executionInfo":{"status":"aborted","timestamp":1744226253165,"user_tz":240,"elapsed":360,"user":{"displayName":"koolgreg2009","userId":"03315174616297252320"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"238b65f2","metadata":{"id":"238b65f2","executionInfo":{"status":"aborted","timestamp":1744226253166,"user_tz":240,"elapsed":360,"user":{"displayName":"koolgreg2009","userId":"03315174616297252320"}}},"outputs":[],"source":["model_3_variables = model_2_variables.copy()\n","\n","model_3_variables.remove(\"sowc_demographics__population-thousands-2021_under-18 X transformer X predicts1\")\n","model_3_variables.remove(\"hdr_region_EAP X xgboost\")\n","model_3_variables.remove(\"fsi_p3:_human_rights X transformer\")\n","model_3_variables.remove(\"sowc_demographics__net-migration-rate-per-1000-population-2021_old-age-dependency-ratio_2020-2030-a X xgboost\")\n","model_3_variables.remove(\"sowc_migration__international-migrant-stock-2020_total-thousands\")\n","model_3_variables.remove(\"fsi_s1:_demographic_pressures X transformer X predicts1\")\n","model_3_variables.remove(\"fsi_p2:_public_services X transformer X predicts1\")\n","model_3_variables.remove(\"fsi_e3:_human_flight_and_brain_drain X transformer X predicts1\")\n","model_3_variables.remove(\"fsi_e3:_human_flight_and_brain_drain X predicts1\")\n","model_3_variables.remove(\"wbi_income_group_Lower middle income\")\n","model_3_variables.remove(\"wbi_income_group_Lower middle income X predicts1\")\n","model_3_variables.remove(\"sowc_demographics__population-thousands-2021_under-18 X transformer\")\n","model_3_variables.remove(\"hdr_region_AS X transformer\")\n","model_3_variables.remove(\"wbi_income_group_Upper middle income X xgboost\")\n","\n","model_3 = sm.OLS(y, sm.add_constant(design_matrix[model_3_variables]))\n","model_3.fit().summary()"]},{"cell_type":"markdown","id":"f18f5d22","metadata":{"id":"f18f5d22"},"source":["We have removed all interactions with a p value greater than 0.\n","This is good! however, the cond number is still too high at 15k. r^2 is around 0.4 which is not bad"]},{"cell_type":"code","execution_count":null,"id":"a2fe5681","metadata":{"id":"a2fe5681","executionInfo":{"status":"aborted","timestamp":1744226253166,"user_tz":240,"elapsed":359,"user":{"displayName":"koolgreg2009","userId":"03315174616297252320"}}},"outputs":[],"source":["model_4_variables = model_3_variables.copy()\n","\n","\n","model_4_variables.remove(\"fsi_c1:_security_apparatus X transformer X predicts1\")\n","model_4_variables.remove(\"transformer X predicts1\")\n","\n","model_4 = sm.OLS(y, sm.add_constant(design_matrix[model_4_variables]))\n","model_4.fit().summary()"]},{"cell_type":"markdown","id":"0bac5ffd","metadata":{"id":"0bac5ffd"},"source":["predicts1 is 1 when the model predicts 1"]},{"cell_type":"markdown","id":"b6b270a4","metadata":{"id":"b6b270a4"},"source":[]},{"cell_type":"markdown","id":"59395748","metadata":{"id":"59395748"},"source":["- Selectively removed indicators which resulted in multicolinearity. Multicolinearity is not a problem anymore, and the model should be good to go and interpretable.\n","- r^2 proportion of test statistic explained. it is the explanatory power of the model and is around 0.3 is adequate :D\n","- p values are all 0, we can stop here for now."]},{"cell_type":"code","execution_count":null,"id":"5c42bcb4","metadata":{"id":"5c42bcb4","executionInfo":{"status":"aborted","timestamp":1744226253167,"user_tz":240,"elapsed":358,"user":{"displayName":"koolgreg2009","userId":"03315174616297252320"}}},"outputs":[],"source":["model_4.fit().params"]},{"cell_type":"markdown","id":"155496f0","metadata":{"id":"155496f0"},"source":["# Final regression equations for the three conflict prediction models:"]},{"cell_type":"markdown","id":"e55b34ea","metadata":{"id":"e55b34ea"},"source":["## $\\hat y_{ffnn} = 0.2031 + 0.0345({demographic\\_pressures})$"]},{"cell_type":"markdown","id":"1decf50f","metadata":{"id":"1decf50f"},"source":["## $\\hat y_{xgboost} = 0.2031 + 0.0345({demographic\\_pressures}) + 0.0936 I_{latin\\_america}(hdr\\_region) + 0.0672I_{[lower\\_middle]}(wbi\\_income\\_group) + 0.0437({security\\_apparatus}) -0.0299({security\\_apparatus) \\times(predicts1})$  "]},{"cell_type":"markdown","id":"e791cfe2","metadata":{"id":"e791cfe2"},"source":["## $\\hat y_{transformer} = 0.2031 + 0.0345({demographic\\_pressures}) -0.030631 ({public\\_services}) + 0.037268(security\\_apparatus)$\n"]},{"cell_type":"code","execution_count":null,"id":"7ce845a0","metadata":{"id":"7ce845a0","executionInfo":{"status":"aborted","timestamp":1744226253167,"user_tz":240,"elapsed":357,"user":{"displayName":"koolgreg2009","userId":"03315174616297252320"}}},"outputs":[],"source":["import plotly.express as px\n","fig = px.scatter(df_oh, )"]},{"cell_type":"markdown","id":"20e9c38b","metadata":{"id":"20e9c38b"},"source":[]},{"cell_type":"markdown","id":"15a51697","metadata":{"id":"15a51697"},"source":["# recommendations:\n","> limitations within model, we did not consider many columns with empty values so most of the dataset"]},{"cell_type":"markdown","id":"ba95914b","metadata":{"id":"ba95914b"},"source":["## Modeling the residuals\n","> We can see that the residuals follow a normal distribution by assumption. We are taking the y minus the y hat, the predicted value of our model. We can see that the normality peaks at the around 0, which is roughly what the mean is of the distrubtion. This follows the assumption of multilinear regression."]},{"cell_type":"code","execution_count":null,"id":"668c9c54","metadata":{"id":"668c9c54","executionInfo":{"status":"aborted","timestamp":1744226253279,"user_tz":240,"elapsed":469,"user":{"displayName":"koolgreg2009","userId":"03315174616297252320"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n"]},{"cell_type":"code","execution_count":null,"id":"eef5460f","metadata":{"id":"eef5460f","executionInfo":{"status":"aborted","timestamp":1744226253280,"user_tz":240,"elapsed":468,"user":{"displayName":"koolgreg2009","userId":"03315174616297252320"}}},"outputs":[],"source":["_ = plt.hist(y-model_4.fit().predict())# y - yhat this is residuals\n","plt.xlabel('Residuals')\n","plt.ylabel('Count')\n","plt.title(\"Barchart of the distribution of residuals\")"]},{"cell_type":"markdown","id":"76bde3f6","metadata":{"id":"76bde3f6"},"source":["## We are plotting the $\\hat y$ against the $y - \\hat y$,"]},{"cell_type":"code","execution_count":null,"id":"2cda0879","metadata":{"id":"2cda0879","executionInfo":{"status":"aborted","timestamp":1744226253288,"user_tz":240,"elapsed":475,"user":{"displayName":"koolgreg2009","userId":"03315174616297252320"}}},"outputs":[],"source":["_ = plt.plot(model_4.fit().predict(), y-model_4.fit().predict(), '.')\n","#x axis is y hat + noise, y is residuals\n","#variance of the residuals appear to be constant, hence follows the assumption of the model\n","#clusters?\n","#bottom are going to -4, top going to 0.6 so variance end up being similar either way\n","plt.xlabel('Predictions')\n","plt.ylabel('Residuals')\n","plt.title(\"Scatterplot of the predictions graphed against the residuals\")"]},{"cell_type":"markdown","id":"990e770b","metadata":{"id":"990e770b"},"source":[]},{"cell_type":"markdown","id":"45130322","metadata":{"id":"45130322"},"source":["# Training and testing:"]},{"cell_type":"code","execution_count":null,"id":"3e04399a","metadata":{"id":"3e04399a","executionInfo":{"status":"aborted","timestamp":1744226253289,"user_tz":240,"elapsed":475,"user":{"displayName":"koolgreg2009","userId":"03315174616297252320"}}},"outputs":[],"source":["np.random.seed(130)\n","train_size = 800\n","data_indices = np.random.choice(design_matrix.index, size=design_matrix.shape[0], replace=False)\n","train_indices = data_indices[train_size:]\n","test_indices = data_indices[:train_size]\n","\n","model_1_train_test_fit = sm.OLS(y[train_indices], sm.add_constant(design_matrix.iloc[train_indices][model_1_variables])).fit()\n","model_1_train_RMSE = ((y[train_indices] - model_1_train_test_fit.predict())**2).mean()**.5\n","model_1_test_RMSE = ((y[test_indices] -\n","                      model_1_train_test_fit.predict(sm.add_constant(design_matrix.iloc[test_indices][model_1_variables]))\n","                     )**2).mean()**.5\n","\n","model_2_train_test_fit = sm.OLS(y[train_indices], sm.add_constant(design_matrix.iloc[train_indices][model_2_variables])).fit()\n","model_2_train_RMSE = ((y[train_indices] - model_2_train_test_fit.predict())**2).mean()**.5\n","model_2_test_RMSE = ((y[test_indices] -\n","                      model_2_train_test_fit.predict(sm.add_constant(design_matrix.iloc[test_indices][model_2_variables]))\n","                     )**2).mean()**.5\n","\n","model_3_train_test_fit = sm.OLS(y[train_indices], sm.add_constant(design_matrix.iloc[train_indices][model_3_variables])).fit()\n","model_3_train_RMSE = ((y[train_indices] - model_3_train_test_fit.predict())**2).mean()**.5\n","model_3_test_RMSE = ((y[test_indices] -\n","                      model_3_train_test_fit.predict(sm.add_constant(design_matrix.iloc[test_indices][model_3_variables]))\n","                     )**2).mean()**.5\n","\n","model_4_train_test_fit = sm.OLS(y[train_indices], sm.add_constant(design_matrix.iloc[train_indices][model_4_variables])).fit()\n","model_4_train_RMSE = ((y[train_indices] - model_4_train_test_fit.predict())**2).mean()**.5\n","model_4_test_RMSE = ((y[test_indices] -\n","                      model_4_train_test_fit.predict(sm.add_constant(design_matrix.iloc[test_indices][model_4_variables]))\n","                     )**2).mean()**.5\n","\n","import plotly.express as px\n","px.bar(pd.DataFrame({'RMSE': [model_1_train_RMSE, model_2_train_RMSE, model_3_train_RMSE, model_4_train_RMSE] +\n","                             [model_1_test_RMSE, model_2_test_RMSE, model_3_test_RMSE, model_4_test_RMSE],\n","                     'Score': ['Training']*4+['Testing']*4,\n","                     'Model': [1,2,3,4]+[1,2,3,4]}),\n","       y='RMSE', x='Model', color='Score', barmode='group', title = \"Bar chart of model performances on training and testing data\")\n"]},{"cell_type":"markdown","id":"c489d7ad","metadata":{"id":"c489d7ad"},"source":["## Notes:\n","\n","> RMSE, or root mean squared error is a metric to assess the performance of a predictive model in a linear regression. The higher the RMSE the farther the predictions of the model is from the actual values.\n","\n","> The RMSE in model 4 is actually higher in comparison to model 3 and the RMSE in model 2 was actually the lowest out of the 4 models. While the increase is RMSE is very minimal, it still suggests that we may have removed useful interactions during our backwards selection process. Interestingly enough, this was not due to overfitting, as the RMSE in the training data went up as well.\n","\n","> Relatively similar RMSE for both training and testing datasets in models 2, 3, and 4 suggests the model is fairly capable of predicting the error rate. However, the condition numbers for model 2 and 3 are is too high, with high multicolinearity present in the model. Hence, it reduces the interpretability of the covariates in the model, since multiple covariates would be influencing the error prediction rate by the same magnitude.\n","\n"]},{"cell_type":"code","execution_count":4,"id":"0936b43d","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"id":"0936b43d","executionInfo":{"status":"error","timestamp":1744226253419,"user_tz":240,"elapsed":3,"user":{"displayName":"koolgreg2009","userId":"03315174616297252320"}},"outputId":"317ced51-aedd-47ae-f073-922e4f2e5341"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'model_3_train_test_fit' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-e7e3cda1cae7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_3_train_test_fit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'model_3_train_test_fit' is not defined"]}],"source":["model_3_train_test_fit.summary().tables[1]"]},{"cell_type":"code","execution_count":null,"id":"90107482","metadata":{"id":"90107482","executionInfo":{"status":"aborted","timestamp":1744226253289,"user_tz":240,"elapsed":475,"user":{"displayName":"koolgreg2009","userId":"03315174616297252320"}}},"outputs":[],"source":["model_4_train_test_fit.summary().tables[1]"]},{"cell_type":"markdown","id":"c753342f","metadata":{"id":"c753342f"},"source":["We see that the p values for some indicators have changed from being 0 to a greater number."]},{"cell_type":"code","execution_count":null,"id":"dc7cf940","metadata":{"id":"dc7cf940","executionInfo":{"status":"aborted","timestamp":1744226253418,"user_tz":240,"elapsed":604,"user":{"displayName":"koolgreg2009","userId":"03315174616297252320"}}},"outputs":[],"source":["reps = 100\n","model_3_train_RMSEs = np.array([0.0]*reps)\n","model_4_train_RMSEs = np.array([0.0]*reps)\n","model_3_test_RMSEs = np.array([0.0]*reps)\n","model_4_test_RMSEs = np.array([0.0]*reps)\n","for i in range(reps):\n","    data_indices = np.random.choice(design_matrix.index, size=design_matrix.shape[0], replace=False)\n","    train_indices = data_indices[train_size:]\n","    test_indices = data_indices[:train_size]\n","\n","    model_3_train_test_fit = sm.OLS(y[train_indices], sm.add_constant(design_matrix.iloc[train_indices][model_3_variables])).fit()\n","    model_3_train_RMSE = ((y[train_indices] - model_3_train_test_fit.predict())**2).mean()**.5\n","    model_3_test_RMSE = ((y[test_indices] -\n","                          model_3_train_test_fit.predict(sm.add_constant(design_matrix.iloc[test_indices][model_3_variables]))\n","                         )**2).mean()**.5\n","    model_3_train_RMSEs[i] = model_3_train_RMSE\n","    model_3_test_RMSEs[i] = model_3_test_RMSE\n","\n","    model_4_train_test_fit = sm.OLS(y[train_indices], sm.add_constant(design_matrix.iloc[train_indices][model_4_variables])).fit()\n","    model_4_train_RMSE = ((y[train_indices] - model_4_train_test_fit.predict())**2).mean()**.5\n","    model_4_test_RMSE = ((y[test_indices] -\n","                          model_4_train_test_fit.predict(sm.add_constant(design_matrix.iloc[test_indices][model_4_variables]))\n","                         )**2).mean()**.5\n","    model_4_train_RMSEs[i] = model_4_train_RMSE\n","    model_4_test_RMSEs[i] = model_4_test_RMSE"]},{"cell_type":"code","execution_count":null,"id":"1e771684","metadata":{"id":"1e771684","executionInfo":{"status":"aborted","timestamp":1744226253419,"user_tz":240,"elapsed":604,"user":{"displayName":"koolgreg2009","userId":"03315174616297252320"}}},"outputs":[],"source":["px.scatter(pd.DataFrame({'Incresed Test RMSE': (model_3_test_RMSEs-model_4_train_RMSEs).tolist()+\n","                                               (model_4_test_RMSEs-model_4_train_RMSEs).tolist(),\n","                         'Training RMSE': model_3_train_RMSEs.tolist()+model_4_train_RMSEs.tolist(),\n","                         'Model': [\"Model 3\"]*reps+[\"Model 4\"]*reps}),\n","           x='Training RMSE', y='Incresed Test RMSE', color='Model',\n","           marginal_x=\"box\", marginal_y=\"violin\",title=\"Performance of model 3 and 4 on testing data\")"]},{"cell_type":"markdown","id":"30c5c6d1","metadata":{"id":"30c5c6d1"},"source":["Its better for the models to predict conflict and then there is no positive than predict no conflict and there is actually conflict. Hence, the prediction error might be more positive.\n"]},{"cell_type":"markdown","id":"4af0abcd","metadata":{"id":"4af0abcd"},"source":["If the coefficient is positive, it increases the error prediction rate on the countries with that attribute. If the coefficinet is negative, then it decreases the prediction error rate, hence the model does well on predicting the error rate."]},{"cell_type":"markdown","id":"07854cf8","metadata":{"id":"07854cf8"},"source":["## Improvements\n","- To further improve our linear regression, we can use forward selection to reintroduce interactions that may have had significance in the error prediction rate of the model.  \n","- While we were careful during the backwards selection process, we still may have removed interactions that had significant relationship to the error prediction rate. We could trace back and see if any labels are worthwhile introducing back to the regression model.\n","- Because we were only able to perform backward selection on a limited amount of indicators, there are plentiful indicators that we did not manage to include in our backward selection process. To expand upon our final model, we could implement forward selection to find the interactions in columns that we did not consider to further increase the statistical power of our regression model."]},{"cell_type":"code","execution_count":null,"id":"ea2c4b91","metadata":{"id":"ea2c4b91","executionInfo":{"status":"aborted","timestamp":1744226253419,"user_tz":240,"elapsed":604,"user":{"displayName":"koolgreg2009","userId":"03315174616297252320"}}},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":5}